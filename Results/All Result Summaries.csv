# ELECTRA base model adversarial attack summary
attack,Exact Match,F1 Score,BLEU Score,Avg Grammatical Errors,Sample Size
No Attack,0.0,0.03494744248046811,0.006323220840012152,1.2473364738945647,86821
AddAny,1.4717786444918684e-05,0.02737975272560318,0.004222451206537618,0.6133195967326515,67945
AddSent,0.0,0.03744256181085773,0.005281502417227407,1.8426521451173743,67945
CEIA,0.0,0.02117154873511893,0.00261252052861048,0.09919963331217826,56724
DPAEG,1.7811659512316764e-05,0.02024763640563221,0.002458716238445574,0.08170208218299699,56143
TextFooler,0.0,0.019824177938182665,0.0024306897856525202,0.14584828246030432,54351

# ELECTRA fine-tuned model adversarial attack summary
attack,Exact Match,F1 Score,BLEU Score,Avg Grammatical Errors,Sample Size
No Attack,0.8121191877541147,0.8947772911474375,0.22851764423765877,0.027424240679098374,86821
AddAny,0.809581278975642,0.887708322952714,0.21283876738884092,0.03779527559055118,67945
AddSent,0.805430863198175,0.8844603651264161,0.21086717749624076,0.03711825741408492,67945
CEIA,0.9022459629081165,0.9192266165820054,0.17151263001095565,0.029634722516042593,56724
DPAEG,0.7550718700461322,0.7916772098759658,0.14224904305158412,0.08451632438594305,56143
TextFooler,0.46602638405917096,0.5300600266041443,0.08459739818270316,0.18798182186160328,54351

# BERT base model adversarial attack summary
attack,Exact Match,F1 Score,BLEU Score,Avg Grammatical Errors,Sample Size
No Attack,6.910770435724076e-05,0.020572318579521996,0.003586023656983772,-0.09422835489109778,86821
AddAny,0.0,0.034222947644290104,0.0060990080618335335,1.4320994922363677,67945
AddSent,1.4717786444918684e-05,0.03191803235475524,0.0057897749614354635,0.7135330046361027,67945
CEIA,7.051688879486637e-05,0.028386760879706766,0.0040579994761100946,0.710810239052253,56724
DPAEG,5.3434978536950285e-05,0.02800864396214491,0.0039032054750860246,0.7011203533833247,56143
TextFooler,3.679785100550128e-05,0.027409513435851296,0.0036551669794070408,0.7868668469761366,54351


# BERT fine-tuned model adversarial attack summary
attack,Exact Match,F1 Score,BLEU Score,Avg Grammatical Errors,Sample Size
No Attack,0.6917566026652539,0.8475391055390096,0.18070631510520044,0.011022678844979901,86821
AddAny,0.6669217749650452,0.8458035280227141,0.16835092927969453,0.029155934947383912,67945
AddSent,0.667142541761719,0.8437430128709541,0.1678485511228276,0.03304143056884245,67945
CEIA,0.7893484239475355,0.8882826395173515,0.14035280560045973,0.021102178971863762,56724
DPAEG,0.635003473273605,0.7325791491835506,0.11084981686721243,0.031562260655825305,56143
TextFooler,0.3699471950838071,0.45081068893301,0.061804264123141085,0.034921160604220715,54351


# RoBERTa base model adversarial attack summary
attack,Exact Match,F1 Score,BLEU Score,Avg Grammatical Errors,Sample Size
No Attack,1.1517950726206793e-05,0.024154382528890905,0.004005284108786294,0.23063544534156483,86821
AddAny,2.9435572889837368e-05,0.03164168119617551,0.005529971851199205,0.7957465597174185,67945
AddSent,1.4717786444918684e-05,0.03900612631358129,0.006885254656416896,1.009213334314519,67945
CEIA,0.0,0.03343694224233241,0.004411680899511421,0.7614766236513645,56724
DPAEG,1.7811659512316764e-05,0.032839898001720914,0.004309490592982661,0.7288352955844896,56143
TextFooler,1.839892550275064e-05,0.030963564427139132,0.003942377139491259,0.683096907140623,54351


# RoBERTa fine-tuned model adversarial attack summary
attack,Exact Match,F1 Score,BLEU Score,Avg Grammatical Errors,Sample Size
No Attack,0.04896280853710508,0.8434036899764924,0.16399294570451592,0.009007037467893712,86821
AddAny,0.05394068732062698,0.8492267252870627,0.15722373296913836,0.005401427625285157,67945
AddSent,0.05369048495106336,0.8413402626344374,0.15419766661235657,0.006269777025535359,67945
CEIA,0.02649672096467104,0.8620666212172634,0.12299700767881132,0.002044989775051125,56724
DPAEG,0.021694601286001817,0.7380670644967877,0.10211398439730526,0.006999982188340487,56143
TextFooler,0.013394417766002465,0.4924565935094415,0.06483543328726252,0.011591323066732903,54351
